{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.distance import correlation\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from contextlib import contextmanager\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "books = pd.read_csv('Books.csv',sep = ';', error_bad_lines = False, encoding = 'latin-1')\n",
    "books.columns = ['ISBN', 'bookTitle', 'bookAuthor', 'yearOfpublication', 'publisher', 'imageUrlS', 'imageUrlM', 'imageUrlL']\n",
    "\n",
    "users = pd.read_csv('Users.csv',sep = ';', error_bad_lines = False, encoding = 'latin-1')\n",
    "users.columns = ['userID','Location','Age']\n",
    "\n",
    "ratings = pd.read_csv('BookRatings.csv', sep = ';', error_bad_lines = False, encoding = 'latin-1')\n",
    "ratings.columns = ['userID','ISBN','bookRating']\n",
    "\n",
    "\n",
    "#Explore the data set and remove unwanted attributes\n",
    "books.drop(['imageUrlS', 'imageUrlM', 'imageUrlL'], axis = 1, inplace = True)\n",
    "books.dtypes\n",
    "#pd.set_option('display.max_colwidth', -1)\n",
    "books.yearOfpublication.unique()\n",
    "\n",
    "#Data validation\n",
    "books.loc[books.ISBN == '0789466953','yearOfpublication'] = 2000\n",
    "books.loc[books.ISBN == '0789466953','bookAuthor'] = 'James Buckley'\n",
    "books.loc[books.ISBN == '0789466953','publisher'] = 'DK Publishing Inc'\n",
    "books.loc[books.ISBN == '0789466953','bookTitle'] = 'DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)'\n",
    "\n",
    "books.loc[books.ISBN == '078946697X','yearOfpublication'] = 2000\n",
    "books.loc[books.ISBN == '078946697X','bookAuthor'] = 'Michael Teitelbaum'\n",
    "books.loc[books.ISBN == '078946697X','publisher'] = 'DK Publishing Inc'\n",
    "books.loc[books.ISBN == '078946697X','bookTitle'] = 'DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)'\n",
    "\n",
    "books.loc[books.ISBN == '2070426769','yearOfpublication'] = 2000\n",
    "books.loc[books.ISBN == '2070426769','bookAuthor'] = 'Jean-Marie Gustave Le ClÃ?Â©zio'\n",
    "books.loc[books.ISBN == '2070426769','publisher'] = 'Gallimard'\n",
    "books.loc[books.ISBN == '2070426769','bookTitle'] = 'Peuple du ciel, suivi de Les Bergers'\n",
    "\n",
    "books.yearOfpublication = pd.to_numeric(books.yearOfpublication, errors = 'coerce')\n",
    "\n",
    "books.loc[(books.yearOfpublication > 2006) | (books.yearOfpublication == 0),'yearOfpublication'] = np.NAN\n",
    "books.yearOfpublication.fillna(round(books.yearOfpublication.mean()), inplace=True)\n",
    "books.yearOfpublication = books.yearOfpublication.astype(np.int32)\n",
    "\n",
    "books.loc[books.publisher.isnull(),'publisher'] = 'other'\n",
    "\n",
    "users.loc[(users.Age < 5) | (users.Age > 90),'Age'] = np.nan\n",
    "users.Age = users.Age.fillna(users.Age.mean()) \n",
    "users.Age = users.Age.astype(np.int32)\n",
    "\n",
    "n_users = users.shape[0]\n",
    "n_books = books.shape[0]\n",
    "\n",
    "ratings_new = ratings[ratings.ISBN.isin(books.ISBN)]\n",
    "ratings_new = ratings_new[ratings_new.userID.isin(users.userID)]\n",
    "\n",
    "sparsity = 1.0 - len(ratings_new)/float(n_users*n_books)\n",
    "print('sparsity level of the dataset = '+str(sparsity*100)+'%')\n",
    "\n",
    "ratings_explicit = ratings_new[ratings_new.bookRating != 0]\n",
    "ratings_implicit = ratings_new[ratings_new.bookRating == 0]\n",
    "\n",
    "users_exp_ratings = users[users.userID.isin(ratings_explicit.userID)]\n",
    "users_imp_ratings = users[users.userID.isin(ratings_implicit.userID)] \n",
    "\n",
    "sns.countplot(data=ratings_explicit, x='bookRating')\n",
    "plt.show()\n",
    "\n",
    "ratings_count = pd.DataFrame(ratings_explicit.groupby(['ISBN'])['bookRating'].sum())\n",
    "top10 = ratings_count.sort_values('bookRating',ascending = False).head(10)\n",
    "#print('Following boooks are recommended: ')\n",
    "#top10.merge(books, left_index = True, right_on = 'ISBN')\n",
    "\n",
    "counts1  = ratings_explicit['userID'].value_counts()\n",
    "ratings_explicit = ratings_explicit[ratings_explicit['userID'].isin(counts1[counts1 >= 100].index)]\n",
    "counts  = ratings_explicit['bookRating'].value_counts()\n",
    "ratings_explicit = ratings_explicit[ratings_explicit['bookRating'].isin(counts[counts >= 100].index)]\n",
    "\n",
    "#Collaborative Filtering based Recommendation System\n",
    "ratings_matrix = ratings_explicit.pivot(index = 'userID', columns = 'ISBN', values = 'bookRating')\n",
    "userID = ratings_matrix.index\n",
    "ISBN = ratings_matrix.columns\n",
    "print(ratings_matrix.shape)\n",
    "ratings_matrix.head()\n",
    "\n",
    "n_users = ratings_matrix.shape[0] #considering only those users who gave explicit ratings\n",
    "n_books = ratings_matrix.shape[1]\n",
    "print (n_users, n_books)\n",
    "\n",
    "#since NaNs cannot be handled by training algorithms, replacing these by 0, which indicates absence of ratings\n",
    "#setting data type\n",
    "ratings_matrix.fillna(0, inplace = True)\n",
    "ratings_matrix = ratings_matrix.astype(np.int32)\n",
    "\n",
    "\n",
    "#checking first few rows\n",
    "ratings_matrix.head(5)\n",
    "\n",
    "#rechecking the sparsity\n",
    "sparsity=1.0-len(ratings_explicit)/float(users_exp_ratings.shape[0]*n_books)\n",
    "print('The sparsity level of Book Crossing dataset is ' +  str(sparsity*100) + ' %')\n",
    "\n",
    "#setting global variables\n",
    "global metric,k\n",
    "k=10\n",
    "metric='cosine'\n",
    "\n",
    "\n",
    "#This function finds k similar users given the user_id and ratings matrix \n",
    "#These similarities are same as obtained via using pairwise_distances\n",
    "def findksimilarusers(user_id, ratings, metric = metric, k=k):\n",
    "    similarities=[]\n",
    "    indices=[]\n",
    "    model_knn = NearestNeighbors(metric = metric, algorithm = 'brute') \n",
    "    model_knn.fit(ratings)\n",
    "    loc = ratings.index.get_loc(user_id)\n",
    "    distances, indices = model_knn.kneighbors(ratings.iloc[loc, :].values.reshape(1, -1), n_neighbors = k+1)\n",
    "    similarities = 1-distances.flatten()\n",
    "            \n",
    "    return similarities,indices\n",
    "\n",
    "\n",
    "#This function predicts rating for specified user-item combination based on user-based approach\n",
    "def predict_userbased(user_id, item_id, ratings, metric = metric, k=k):\n",
    "    prediction=0\n",
    "    user_loc = ratings.index.get_loc(user_id)\n",
    "    item_loc = ratings.columns.get_loc(item_id)\n",
    "    similarities, indices=findksimilarusers(user_id, ratings,metric, k) #similar users based on cosine similarity\n",
    "    mean_rating = ratings.iloc[user_loc,:].mean() #to adjust for zero based indexing\n",
    "    sum_wt = np.sum(similarities)-1\n",
    "    product=1\n",
    "    wtd_sum = 0 \n",
    "    \n",
    "    for i in range(0, len(indices.flatten())):\n",
    "        if indices.flatten()[i] == user_loc:\n",
    "            continue;\n",
    "        else: \n",
    "            ratings_diff = ratings.iloc[indices.flatten()[i],item_loc]-np.mean(ratings.iloc[indices.flatten()[i],:])\n",
    "            product = ratings_diff * (similarities[i])\n",
    "            wtd_sum = wtd_sum + product\n",
    "    \n",
    "    #in case of very sparse datasets, using correlation metric for collaborative based approach may give negative ratings\n",
    "    #which are handled here as below\n",
    "    if prediction <= 0:\n",
    "        prediction = 1   \n",
    "    elif prediction >10:\n",
    "        prediction = 10\n",
    "    \n",
    "    prediction = int(round(mean_rating + (wtd_sum/sum_wt)))\n",
    "    print('\\nPredicted rating for user {0} -> item {1}: {2}'.format(user_id,item_id,prediction))\n",
    "\n",
    "    return prediction\n",
    "\n",
    "predict_userbased(11676,'0001056107',ratings_matrix);\n",
    "\n",
    "#This function finds k similar items given the item_id and ratings matrix\n",
    "\n",
    "def findksimilaritems(item_id, ratings, metric=metric, k=k):\n",
    "    similarities=[]\n",
    "    indices=[]\n",
    "    ratings=ratings.T\n",
    "    loc = ratings.index.get_loc(item_id)\n",
    "    model_knn = NearestNeighbors(metric = metric, algorithm = 'brute')\n",
    "    model_knn.fit(ratings)\n",
    "    \n",
    "    distances, indices = model_knn.kneighbors(ratings.iloc[loc, :].values.reshape(1, -1), n_neighbors = k+1)\n",
    "    similarities = 1-distances.flatten()\n",
    "\n",
    "    return similarities,indices\n",
    "\n",
    "similarities,indices=findksimilaritems('0001056107',ratings_matrix)\n",
    "\n",
    "\n",
    "\n",
    "#This function predicts the rating for specified user-item combination based on item-based approach\n",
    "def predict_itembased(user_id, item_id, ratings, metric = metric, k=k):\n",
    "    prediction= wtd_sum =0\n",
    "    user_loc = ratings.index.get_loc(user_id)\n",
    "    item_loc = ratings.columns.get_loc(item_id)\n",
    "    similarities, indices=findksimilaritems(item_id, ratings) #similar users based on correlation coefficients\n",
    "    sum_wt = np.sum(similarities)-1\n",
    "    product=1\n",
    "    for i in range(0, len(indices.flatten())):\n",
    "        if indices.flatten()[i] == item_loc:\n",
    "            continue;\n",
    "        else:\n",
    "            product = ratings.iloc[user_loc,indices.flatten()[i]] * (similarities[i])\n",
    "            wtd_sum = wtd_sum + product                              \n",
    "    prediction = int(round(wtd_sum/sum_wt))\n",
    "    \n",
    "    #in case of very sparse datasets, using correlation metric for collaborative based approach may give negative ratings\n",
    "    #which are handled here as below //code has been validated without the code snippet below, below snippet is to avoid negative\n",
    "    #predictions which might arise in case of very sparse datasets when using correlation metric\n",
    "    if prediction <= 0:\n",
    "        prediction = 1   \n",
    "    elif prediction >10:\n",
    "        prediction = 10\n",
    "\n",
    "    print('\\nPredicted rating for user {0} -> item {1}: {2}'.format(user_id,item_id,prediction))   \n",
    "    \n",
    "    return prediction\n",
    "\n",
    "prediction = predict_itembased(11676,'0001056107',ratings_matrix)\n",
    "\n",
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            \n",
    "            \n",
    "#This function utilizes above functions to recommend items for item/user based approach and cosine/correlation. \n",
    "#Recommendations are made if the predicted rating for an item is >= to 6,and the items have not been rated alreadydef recommendItem(user_id, ratings, metric=metric):    \n",
    "def recommendItem(user_id, ratings, metric=metric):\n",
    "    if (user_id not in ratings.index.values) or type(user_id) is not int:\n",
    "        print(\"User id should be a valid integer from this list :\\n\\n {} \".format(re.sub('[\\[\\]]', '', np.array_str(ratings_matrix.index.values))))\n",
    "    else:    \n",
    "        ids = ['Item-based (correlation)','Item-based (cosine)','User-based (correlation)','User-based (cosine)']\n",
    "        select = widgets.Dropdown(options=ids, value=ids[0],description='Select approach', width='1000px')\n",
    "        def on_change(change):\n",
    "            clear_output(wait=True)\n",
    "            prediction = []            \n",
    "            if change['type'] == 'change' and change['name'] == 'value':            \n",
    "                if (select.value == 'Item-based (correlation)') | (select.value == 'User-based (correlation)') :\n",
    "                    metric = 'correlation'\n",
    "                else:                       \n",
    "                    metric = 'cosine'   \n",
    "                with suppress_stdout():\n",
    "                    if (select.value == 'Item-based (correlation)') | (select.value == 'Item-based (cosine)'):\n",
    "                        for i in range(ratings.shape[1]):\n",
    "                            if (ratings[str(ratings.columns[i])][user_id] !=0): #not rated already\n",
    "                                prediction.append(predict_itembased(user_id, str(ratings.columns[i]) ,ratings, metric))\n",
    "                            else:                    \n",
    "                                prediction.append(-1) #for already rated items\n",
    "                    else:\n",
    "                        for i in range(ratings.shape[1]):\n",
    "                            if (ratings[str(ratings.columns[i])][user_id] !=0): #not rated already\n",
    "                                prediction.append(predict_userbased(user_id, str(ratings.columns[i]) ,ratings, metric))\n",
    "                            else:                    \n",
    "                                prediction.append(-1) #for already rated items\n",
    "                prediction = pd.Series(prediction)\n",
    "                prediction = prediction.sort_values(ascending=False)\n",
    "                recommended = prediction[:10]\n",
    "                print(\"As per {0} approach....Following books are recommended...\".format(select.value))\n",
    "                for i in range(len(recommended)):\n",
    "                     print(\"{0}. {1}\".format(i+1,books.bookTitle[recommended.index[i]].encode('utf-8')))                       \n",
    "        select.observe(on_change)\n",
    "        display(select)\n",
    "        \n",
    "recommendItem(4385, ratings_matrix)\n",
    "\n",
    "recommendItem(4385, ratings_matrix)\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
